import os
import shutil
import fitz # Importado para extrair texto de PDFs
import pandas as pd
from pdf2image import convert_from_path
import easyocr
import numpy as np
from fuzzywuzzy import fuzz
import unicodedata
import re
from concurrent.futures import ThreadPoolExecutor, as_completed
import logging
 
# --- Configura√ß√£o de Logging ---
# Configura o sistema de log para mostrar informa√ß√µes no console.
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
 
# --- Configura√ß√µes Principais ---
# Inicializa o leitor EasyOCR uma √∫nica vez para portugu√™s, sem usar GPU.
# Isso economiza tempo e recursos.
reader = easyocr.Reader(['pt'], gpu=False)
 
# Caminho para o execut√°vel Poppler. Essencial para o pdf2image funcionar.
poppler_path = r"C:\Users\2160036544\Downloads\Release-24.08.0-0\poppler-24.08.0\Library\bin"
 
# Lista de palavras-chave a serem buscadas nos documentos.
palavras_chave = [
    "ades√£o de beneficios no processo admissional",
    "solicita√ß√£o de transporte",
    "inclus√£o, solicita√ß√£o e cancelamento vale transporte via varejo",
    "Extrato de beneficios",
    "Vale transporte",
    "Adesao",
    "RH - CONTRATO DE TRABALHO - ADESAO",
    "EXCLUSAO DO VALE TRANSPORTE",
    "RH - ANEXOS",
    "RH - BENEFICIOS",
    "RH - CONTRATO DE TRABALHO - ADESAO",
    "Ades√£o de Benef√≠cios no Processo Admissional Via Varejo e VVLOG",
    "Altera√ß√£o, Inclus√£o e Exclus√£o de vale transporte",
]
 
# Caminhos das pastas e arquivo de sa√≠da.
pasta_principal = r"C:\Users\2160036544\Downloads\Arquivos_Descompactados\2160036544---N-64342692----30-05-2025-16-56-01"
saida_excel = r"C:\Users\2160036544\Downloads\Arquivos_Descompactados"
 
# Cria a pasta para PDFs encontrados se ela n√£o existir.
pasta_encontrados = os.path.join(pasta_principal, "Encontrados")
os.makedirs(pasta_encontrados, exist_ok=True)
 
# Lista para armazenar os resultados do processamento de cada PDF.
resultados = []
 
# --- Fun√ß√µes Auxiliares ---
def normalizar(texto):
    """
    Normaliza o texto removendo acentos, convertendo para min√∫sculas
    e retirando caracteres especiais.
    """
    texto = unicodedata.normalize('NFD', texto)
    texto = texto.encode('ascii', 'ignore').decode('utf-8')
    texto = re.sub(r'[^a-zA-Z0-9\s]', '', texto)
    return texto.lower().strip()
 
def contem_palavra_chave(texto_normalizado):
    """
    Verifica se o texto normalizado cont√©m alguma das palavras-chave
    usando a correspond√™ncia fuzzy (similaridade parcial).
    Um limiar de 85 significa que 85% do texto da chave deve corresponder.
    """
    for chave in palavras_chave:
        chave_norm = normalizar(chave)
        if fuzz.partial_ratio(chave_norm, texto_normalizado) >= 85:
            return True
    return False
 
def extrair_texto_fitz(caminho_pdf):
    """
    Tenta extrair texto diretamente de um PDF usando PyMuPDF (Fitz).
    √â muito mais r√°pido para PDFs com camada de texto.
    """
    texto = ""
    try:
        doc = fitz.open(caminho_pdf)
        for page in doc:
            texto += page.get_text() # Extrai texto da p√°gina
        doc.close()
        return normalizar(texto)
    except Exception as e:
        # Se ocorrer um erro (ex: PDF corrompido, protegido), registre e retorne None.
        # N√≠vel DEBUG para n√£o poluir o console com erros esperados de PDFs sem texto.
        logging.debug(f"Erro ao extrair texto com Fitz de {caminho_pdf}: {e}")
        return None # Indica que Fitz n√£o conseguiu extrair texto ou houve um erro
 
def extrair_texto_easyocr(caminho_pdf):
    """
    Extrai texto de um PDF usando EasyOCR ap√≥s converter as p√°ginas em imagens.
    Usado para PDFs que s√£o primariamente imagens (escaneados).
    O DPI (Dots Per Inch) afeta a qualidade da imagem e o consumo de recursos.
    Valores como 150 ou 120 podem ser mais leves que 200, mas teste a precis√£o.
    """
    texto_total = ""
    try:
        # Tente 150 ou 120 DPI para menos consumo de recursos,
        # mas verifique se a precis√£o do OCR se mant√©m.
        imagens = convert_from_path(caminho_pdf, dpi=150, poppler_path=poppler_path)
        for img in imagens:
            # Converte a imagem para um array numpy e passa para o EasyOCR.
            resultado = reader.readtext(np.array(img), detail=0)
            texto_total += " ".join(resultado) + " "
    except Exception as e:
        logging.error(f"Erro na convers√£o OCR de {caminho_pdf}: {e}")
    return normalizar(texto_total)
 
def processar_pdf(caminho_pdf):
    """
    Fun√ß√£o principal para processar um √∫nico PDF.
    Primeiro tenta extra√ß√£o de texto com Fitz, se falhar, usa EasyOCR.
    """
    try:
        nome_arquivo = os.path.basename(caminho_pdf)
        pasta_matricula = os.path.basename(os.path.dirname(caminho_pdf))
 
        # --- Otimiza√ß√£o: Filtro Inicial por Nome do Arquivo ---
        # Ignora PDFs que provavelmente n√£o cont√™m as palavras-chave com base no nome.
        # Isso evita processamento pesado (OCR) em arquivos irrelevantes.
        if not any(x in normalizar(nome_arquivo) for x in ["contrato de trabalho - adesao", "extrato de beneficios", "vale transporte", "beneficio", "adesao", "rh - anexos", "rh - beneficios","rh - contrato de trabalho - adesao"]):
            return [pasta_matricula, "Ignorado (Filtrado por Nome)", caminho_pdf]
 
        # --- Estrat√©gia H√≠brida: Tentar Fitz Primeiro ---
        texto_extraido_fitz = extrair_texto_fitz(caminho_pdf)
        if texto_extraido_fitz and contem_palavra_chave(texto_extraido_fitz):
            status = "Encontrado (via Fitz)"
            destino = os.path.join(pasta_encontrados, nome_arquivo)
            shutil.copy2(caminho_pdf, destino)
            logging.info(f"Copiado: {caminho_pdf} para {destino}")
            return [pasta_matricula, status, caminho_pdf]
 
        # --- Recorrer ao EasyOCR se Fitz falhar ou n√£o encontrar ---
        # Isso significa que o PDF √© uma imagem ou o texto n√£o foi detect√°vel por Fitz.
        logging.info(f"Fitz n√£o encontrou ou n√£o conseguiu ler, usando OCR para: {nome_arquivo}")
        texto_extraido_ocr = extrair_texto_easyocr(caminho_pdf)
        achou_ocr = contem_palavra_chave(texto_extraido_ocr)
        status = "Encontrado (via OCR)" if achou_ocr else "N√£o encontrado"
 
        if achou_ocr:
            destino = os.path.join(pasta_encontrados, nome_arquivo)
            shutil.copy2(caminho_pdf, destino)
            logging.info(f"Copiado: {caminho_pdf} para {destino}")
 
        return [pasta_matricula, status, caminho_pdf]
 
    except Exception as e:
        logging.error(f"Erro geral ao processar {caminho_pdf}: {e}", exc_info=True) # exc_info=True para detalhes do erro
        return [os.path.basename(os.path.dirname(caminho_pdf)), f"Erro: {e}", caminho_pdf]
 
# --- Fun√ß√£o Principal de Busca ---
def buscar_com_threads(pasta):
    """
    Percorre o diret√≥rio, encontra todos os PDFs e os processa
    usando um pool de threads para paraleliza√ß√£o.
    """
    pdfs = []
    for raiz, _, arquivos in os.walk(pasta):
        for arquivo in arquivos:
            if arquivo.lower().endswith('.pdf'):
                pdfs.append(os.path.join(raiz, arquivo))
 
    logging.info(f"üîç Total de PDFs a processar: {len(pdfs)}")
 
    # Otimiza√ß√£o: Define o n√∫mero de threads para um valor ideal para o seu CPU (4 n√∫cleos).
    # Isso evita sobrecarga e mant√©m o sistema responsivo.
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [executor.submit(processar_pdf, pdf) for pdf in pdfs]
        for i, future in enumerate(as_completed(futures)):
            try:
                resultado = future.result()
                resultados.append(resultado)
                # Relata o progresso a cada 10 arquivos ou ao final.
                if (i + 1) % 10 == 0 or (i + 1) == len(pdfs):
                    logging.info(f"Progresso: {i + 1}/{len(pdfs)} PDFs processados. √öltimo: {resultado[0]} - {resultado[1]}")
            except Exception as e:
                logging.error(f"Erro ao obter resultado de uma thread: {e}", exc_info=True)
 
# --- Execu√ß√£o do Script ---
if __name__ == "__main__":
    logging.info("Iniciando a busca otimizada de documentos...")
    buscar_com_threads(pasta_principal)
 
    # Cria um DataFrame do pandas com os resultados e salva em Excel.
    df = pd.DataFrame(resultados, columns=["Matr√≠cula", "Status", "Caminho"])
    df.to_excel(saida_excel, index=False)
 
    logging.info("‚úÖ Busca otimizada finalizada.")
    logging.info(f"üìÅ Planilha de resultados gerada em: {saida_excel}")